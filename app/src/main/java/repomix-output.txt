This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-28T05:57:18.820Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

================================================================
Directory Structure
================================================================
com/parakurom/lingoflow/AutoReadFragment.kt
com/parakurom/lingoflow/CameraFragment.kt
com/parakurom/lingoflow/GestureRecognizerHelper.kt
com/parakurom/lingoflow/GestureRecognizerResultsAdapter.kt
com/parakurom/lingoflow/MainActivity.kt
com/parakurom/lingoflow/OverlayView.kt
com/parakurom/lingoflow/PermissionsFragment.kt
com/parakurom/lingoflow/WelcomeFragment.kt

================================================================
Files
================================================================

================
File: com/parakurom/lingoflow/AutoReadFragment.kt
================
package com.parakurom.lingoflow

import android.content.Context
import android.graphics.*
import android.os.Bundle
import android.speech.tts.TextToSpeech
import android.util.AttributeSet
import android.util.Log
import android.view.*
import android.widget.Button
import android.widget.SeekBar
import android.widget.TextView
import android.widget.Toast
import androidx.camera.core.*
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.camera.view.PreviewView
import androidx.core.content.ContextCompat
import androidx.core.widget.NestedScrollView
import androidx.fragment.app.Fragment
import com.google.android.material.bottomsheet.BottomSheetBehavior
import com.google.android.material.floatingactionbutton.FloatingActionButton
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.text.Text
import com.google.mlkit.vision.text.TextRecognition
import com.google.mlkit.vision.text.latin.TextRecognizerOptions
import java.util.*
import java.util.concurrent.ExecutorService
import java.util.concurrent.Executors

class AutoReadFragment : Fragment() {

    private lateinit var viewFinder: PreviewView
    private lateinit var recognizedTextView: TextView
    private lateinit var bottomSheet: NestedScrollView
    private lateinit var bottomSheetBehavior: BottomSheetBehavior<NestedScrollView>
    private lateinit var captureButton: FloatingActionButton
    private lateinit var restartTtsButton: Button
    private lateinit var stopTtsButton: Button
    private lateinit var seekBarPitch: SeekBar
    private lateinit var seekBarSpeed: SeekBar
    private lateinit var roiView: RegionOfInterestView

    private var imageCapture: ImageCapture? = null
    private lateinit var cameraExecutor: ExecutorService
    private val textRecognizer = TextRecognition.getClient(TextRecognizerOptions.DEFAULT_OPTIONS)
    private var textToSpeech: TextToSpeech? = null
    private var lastRecognizedText: String = ""
    private var isSpeaking: Boolean = false

    // Image processing variables
    private var capturedBitmap: Bitmap? = null
    private var imageWidth: Int = 0
    private var imageHeight: Int = 0

    override fun onCreateView(
        inflater: LayoutInflater, container: ViewGroup?, savedInstanceState: Bundle?
    ): View {
        val view = inflater.inflate(R.layout.fragment_auto_read, container, false)

        viewFinder = view.findViewById(R.id.view_finder)
        bottomSheet = view.findViewById(R.id.bottom_sheet)
        recognizedTextView = view.findViewById(R.id.recognized_text)
        captureButton = view.findViewById(R.id.capture_button)
        restartTtsButton = view.findViewById(R.id.restart_tts_button)
        stopTtsButton = view.findViewById(R.id.stop_tts_button)
        seekBarPitch = view.findViewById(R.id.seekBarPitch)
        seekBarSpeed = view.findViewById(R.id.seekBarSpeed)
        roiView = view.findViewById(R.id.roi_view)

        return view
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        super.onViewCreated(view, savedInstanceState)

        // Initialize bottom sheet behavior
        bottomSheetBehavior = BottomSheetBehavior.from(bottomSheet)
        bottomSheetBehavior.state = BottomSheetBehavior.STATE_COLLAPSED

        cameraExecutor = Executors.newSingleThreadExecutor()
        startCamera()

        initializeTextToSpeech()

        captureButton.setOnClickListener {
            captureImage()
        }

        restartTtsButton.setOnClickListener {
            restartTextToSpeech()
        }

        stopTtsButton.setOnClickListener {
            stopTextToSpeech()
        }

        seekBarPitch.setOnSeekBarChangeListener(object : SeekBar.OnSeekBarChangeListener {
            override fun onProgressChanged(seekBar: SeekBar?, progress: Int, fromUser: Boolean) {
                if (fromUser) {
                    setPitch(progress / 50f)
                    // Re-speak text with new pitch if currently speaking
                    if (isSpeaking && lastRecognizedText.isNotEmpty()) {
                        restartTextToSpeech()
                    }
                }
            }
            override fun onStartTrackingTouch(seekBar: SeekBar?) {}
            override fun onStopTrackingTouch(seekBar: SeekBar?) {}
        })

        seekBarSpeed.setOnSeekBarChangeListener(object : SeekBar.OnSeekBarChangeListener {
            override fun onProgressChanged(seekBar: SeekBar?, progress: Int, fromUser: Boolean) {
                if (fromUser) {
                    setSpeechRate(progress / 50f)
                    // Re-speak text with new speed if currently speaking
                    if (isSpeaking && lastRecognizedText.isNotEmpty()) {
                        restartTextToSpeech()
                    }
                }
            }
            override fun onStartTrackingTouch(seekBar: SeekBar?) {}
            override fun onStopTrackingTouch(seekBar: SeekBar?) {}
        })
    }

    private fun initializeTextToSpeech() {
        textToSpeech = TextToSpeech(requireContext()) { status ->
            if (status == TextToSpeech.SUCCESS) {
                textToSpeech?.language = Locale.ENGLISH
                textToSpeech?.setOnUtteranceCompletedListener {
                    activity?.runOnUiThread {
                        isSpeaking = false
                        updateButtonStates()
                    }
                }
            } else {
                Log.e("AutoReadFragment", "TextToSpeech initialization failed")
                Toast.makeText(requireContext(), "TTS Initialization Failed", Toast.LENGTH_SHORT).show()
            }
        }
    }

    private fun startCamera() {
        val cameraProviderFuture = ProcessCameraProvider.getInstance(requireContext())

        cameraProviderFuture.addListener({
            try {
                val cameraProvider: ProcessCameraProvider = cameraProviderFuture.get()
                val cameraSelector = CameraSelector.DEFAULT_BACK_CAMERA

                val preview = Preview.Builder().build().also {
                    it.setSurfaceProvider(viewFinder.surfaceProvider)
                }

                imageCapture = ImageCapture.Builder().build()

                cameraProvider.unbindAll()
                cameraProvider.bindToLifecycle(this, cameraSelector, preview, imageCapture)

                // Get preview dimensions to set initial ROI size
                viewFinder.post {
                    roiView.setInitialRoi(viewFinder.width, viewFinder.height)
                }

            } catch (e: Exception) {
                Log.e("AutoReadFragment", "Camera binding failed", e)
                Toast.makeText(requireContext(), "Camera initialization failed", Toast.LENGTH_LONG).show()
            }
        }, ContextCompat.getMainExecutor(requireContext()))
    }

    private fun captureImage() {
        val imageCapture = imageCapture ?: run {
            Log.e("AutoReadFragment", "ImageCapture is not initialized")
            Toast.makeText(requireContext(), "Camera is not ready yet", Toast.LENGTH_SHORT).show()
            return
        }

        imageCapture.takePicture(
            ContextCompat.getMainExecutor(requireContext()),
            object : ImageCapture.OnImageCapturedCallback() {
                override fun onCaptureSuccess(imageProxy: ImageProxy) {
                    processImageWithROI(imageProxy)
                }

                override fun onError(exception: ImageCaptureException) {
                    Log.e("AutoReadFragment", "Image capture failed", exception)
                    Toast.makeText(requireContext(), "Image capture failed", Toast.LENGTH_SHORT).show()
                }
            }
        )
    }

    private fun processImageWithROI(imageProxy: ImageProxy) {
        val mediaImage = imageProxy.image
        if (mediaImage != null) {
            // Convert the image to a bitmap
            val bitmap = imageToBitmap(mediaImage, imageProxy.imageInfo.rotationDegrees)
            capturedBitmap = bitmap
            imageWidth = bitmap.width
            imageHeight = bitmap.height

            // Calculate ROI coordinates relative to the captured image
            val roi = calculateROIRect(bitmap.width, bitmap.height)

            // Crop the bitmap to the ROI
            val croppedBitmap = cropBitmap(bitmap, roi)

            // Create InputImage from cropped bitmap
            val image = InputImage.fromBitmap(croppedBitmap, 0)

            textRecognizer.process(image)
                .addOnSuccessListener { visionText -> displayText(visionText) }
                .addOnFailureListener { e ->
                    Log.e("AutoReadFragment", "OCR failed", e)
                    Toast.makeText(requireContext(), "Text recognition failed", Toast.LENGTH_SHORT).show()
                }
                .addOnCompleteListener { imageProxy.close() }
        }
    }

    private fun imageToBitmap(mediaImage: android.media.Image, rotation: Int): Bitmap {
        val buffer = mediaImage.planes[0].buffer
        val bytes = ByteArray(buffer.remaining())
        buffer.get(bytes)

        val bitmap = BitmapFactory.decodeByteArray(bytes, 0, bytes.size)

        // Rotate the bitmap if needed
        return if (rotation != 0) {
            val matrix = Matrix()
            matrix.postRotate(rotation.toFloat())
            Bitmap.createBitmap(bitmap, 0, 0, bitmap.width, bitmap.height, matrix, true)
        } else {
            bitmap
        }
    }

    private fun calculateROIRect(imageWidth: Int, imageHeight: Int): Rect {
        // Get ROI relative coordinates (0.0-1.0)
        val relativeRect = roiView.getRelativeCoordinates()

        // Convert to actual pixel coordinates in the captured image
        return Rect(
            (relativeRect.left * imageWidth).toInt(),
            (relativeRect.top * imageHeight).toInt(),
            (relativeRect.right * imageWidth).toInt(),
            (relativeRect.bottom * imageHeight).toInt()
        )
    }

    private fun cropBitmap(bitmap: Bitmap, roi: Rect): Bitmap {
        // Make sure the ROI is within bounds
        val safeRect = Rect(
            roi.left.coerceIn(0, bitmap.width),
            roi.top.coerceIn(0, bitmap.height),
            roi.right.coerceIn(0, bitmap.width),
            roi.bottom.coerceIn(0, bitmap.height)
        )

        // Check if the ROI has valid dimensions
        if (safeRect.width() <= 0 || safeRect.height() <= 0) {
            // Return the original bitmap if ROI is invalid
            return bitmap
        }

        return Bitmap.createBitmap(
            bitmap,
            safeRect.left,
            safeRect.top,
            safeRect.width(),
            safeRect.height()
        )
    }

    private fun displayText(visionText: Text) {
        activity?.runOnUiThread {
            lastRecognizedText = visionText.text

            if (lastRecognizedText.isNotEmpty()) {
                recognizedTextView.text = lastRecognizedText

                // Expand bottom sheet to show the text
                bottomSheetBehavior.state = BottomSheetBehavior.STATE_EXPANDED

                // Start speaking automatically on capture
                startTextToSpeech()
            } else {
                Toast.makeText(requireContext(), "No text detected in the selected area", Toast.LENGTH_SHORT).show()
            }
        }
    }

    private fun startTextToSpeech() {
        if (lastRecognizedText.isEmpty()) {
            Toast.makeText(requireContext(), "No text to read", Toast.LENGTH_SHORT).show()
            return
        }

        val params = HashMap<String, String>()
        params[TextToSpeech.Engine.KEY_PARAM_UTTERANCE_ID] = "speechId"

        textToSpeech?.speak(lastRecognizedText, TextToSpeech.QUEUE_FLUSH, params)
        isSpeaking = true
        updateButtonStates()
    }

    private fun stopTextToSpeech() {
        if (isSpeaking) {
            textToSpeech?.stop()
            isSpeaking = false
            updateButtonStates()
        }
    }

    private fun restartTextToSpeech() {
        stopTextToSpeech()
        startTextToSpeech()
    }

    private fun updateButtonStates() {
        // Enable/disable buttons based on state
        stopTtsButton.isEnabled = isSpeaking
        restartTtsButton.isEnabled = lastRecognizedText.isNotEmpty()
    }

    private fun setPitch(pitch: Float) {
        textToSpeech?.setPitch(pitch)
    }

    private fun setSpeechRate(rate: Float) {
        textToSpeech?.setSpeechRate(rate)
    }

    override fun onDestroyView() {
        super.onDestroyView()
        cameraExecutor.shutdown()
        textToSpeech?.stop()
        textToSpeech?.shutdown()
    }
}

/**
 * Custom view for Region of Interest selection
 */
class RegionOfInterestView @JvmOverloads constructor(
    context: Context, attrs: AttributeSet? = null, defStyleAttr: Int = 0
) : View(context, attrs, defStyleAttr) {

    // ROI rectangle (in view coordinates)
    private val roiRect = RectF()

    // For touch handling
    private var activePointerId = MotionEvent.INVALID_POINTER_ID
    private var isResizing = false
    private var isMoving = false
    private val lastTouchPoint = PointF()
    private val resizeHandleSize = 80f

    // For drawing
    private val roiPaint = Paint().apply {
        color = Color.WHITE
        style = Paint.Style.STROKE
        strokeWidth = 4f
        isAntiAlias = true
    }

    private val backgroundPaint = Paint().apply {
        color = Color.parseColor("#80000000") // Semi-transparent black
        style = Paint.Style.FILL
    }

    private val handlePaint = Paint().apply {
        color = Color.WHITE
        style = Paint.Style.FILL
        isAntiAlias = true
    }

    fun setInitialRoi(viewWidth: Int, viewHeight: Int) {
        // Set initial ROI to center 70% of the view
        val roiWidth = viewWidth * 0.7f
        val roiHeight = viewHeight * 0.3f  // Good for text which is usually wider than tall

        roiRect.left = (viewWidth - roiWidth) / 2
        roiRect.top = (viewHeight - roiHeight) / 2
        roiRect.right = roiRect.left + roiWidth
        roiRect.bottom = roiRect.top + roiHeight

        invalidate()
    }

    // Get ROI in relative coordinates (0.0-1.0)
    fun getRelativeCoordinates(): RectF {
        return RectF(
            roiRect.left / width,
            roiRect.top / height,
            roiRect.right / width,
            roiRect.bottom / height
        )
    }

    override fun onDraw(canvas: Canvas) {
        super.onDraw(canvas)

        // Draw semi-transparent background outside ROI
        // Top
        canvas.drawRect(0f, 0f, width.toFloat(), roiRect.top, backgroundPaint)
        // Left
        canvas.drawRect(0f, roiRect.top, roiRect.left, roiRect.bottom, backgroundPaint)
        // Right
        canvas.drawRect(roiRect.right, roiRect.top, width.toFloat(), roiRect.bottom, backgroundPaint)
        // Bottom
        canvas.drawRect(0f, roiRect.bottom, width.toFloat(), height.toFloat(), backgroundPaint)

        // Draw ROI rectangle
        canvas.drawRect(roiRect, roiPaint)

        // Draw resize handles at corners
        val handleRadius = resizeHandleSize / 4
        canvas.drawCircle(roiRect.left, roiRect.top, handleRadius, handlePaint)
        canvas.drawCircle(roiRect.right, roiRect.top, handleRadius, handlePaint)
        canvas.drawCircle(roiRect.left, roiRect.bottom, handleRadius, handlePaint)
        canvas.drawCircle(roiRect.right, roiRect.bottom, handleRadius, handlePaint)
    }

    override fun onTouchEvent(event: MotionEvent): Boolean {
        when (event.actionMasked) {
            MotionEvent.ACTION_DOWN -> {
                activePointerId = event.getPointerId(0)
                lastTouchPoint.set(event.x, event.y)

                // Check if touch is on a resize handle or inside the ROI
                isResizing = isOnResizeHandle(lastTouchPoint.x, lastTouchPoint.y)
                isMoving = !isResizing && roiRect.contains(lastTouchPoint.x, lastTouchPoint.y)
            }

            MotionEvent.ACTION_MOVE -> {
                val pointerIndex = event.findPointerIndex(activePointerId)
                if (pointerIndex != -1) {
                    val currentX = event.getX(pointerIndex)
                    val currentY = event.getY(pointerIndex)
                    val dx = currentX - lastTouchPoint.x
                    val dy = currentY - lastTouchPoint.y

                    if (isResizing) {
                        resizeROI(lastTouchPoint.x, lastTouchPoint.y, currentX, currentY)
                    } else if (isMoving) {
                        moveROI(dx, dy)
                    }

                    lastTouchPoint.set(currentX, currentY)
                    invalidate()
                }
            }

            MotionEvent.ACTION_UP, MotionEvent.ACTION_CANCEL -> {
                activePointerId = MotionEvent.INVALID_POINTER_ID
                isResizing = false
                isMoving = false
            }
        }

        return true
    }

    private fun isOnResizeHandle(x: Float, y: Float): Boolean {
        // Check if touch point is near any of the corners
        val tolerance = resizeHandleSize / 2

        // Top-left
        if (Math.abs(x - roiRect.left) <= tolerance && Math.abs(y - roiRect.top) <= tolerance) {
            return true
        }
        // Top-right
        if (Math.abs(x - roiRect.right) <= tolerance && Math.abs(y - roiRect.top) <= tolerance) {
            return true
        }
        // Bottom-left
        if (Math.abs(x - roiRect.left) <= tolerance && Math.abs(y - roiRect.bottom) <= tolerance) {
            return true
        }
        // Bottom-right
        if (Math.abs(x - roiRect.right) <= tolerance && Math.abs(y - roiRect.bottom) <= tolerance) {
            return true
        }

        return false
    }

    private fun resizeROI(startX: Float, startY: Float, currentX: Float, currentY: Float) {
        // Determine which corner is being dragged
        val isLeftSide = Math.abs(startX - roiRect.left) <= resizeHandleSize / 2
        val isRightSide = Math.abs(startX - roiRect.right) <= resizeHandleSize / 2
        val isTopSide = Math.abs(startY - roiRect.top) <= resizeHandleSize / 2
        val isBottomSide = Math.abs(startY - roiRect.bottom) <= resizeHandleSize / 2

        // Constrain to view bounds
        val newX = currentX.coerceIn(0f, width.toFloat())
        val newY = currentY.coerceIn(0f, height.toFloat())

        // Update the appropriate sides
        if (isLeftSide) roiRect.left = Math.min(newX, roiRect.right - 100)
        if (isRightSide) roiRect.right = Math.max(newX, roiRect.left + 100)
        if (isTopSide) roiRect.top = Math.min(newY, roiRect.bottom - 100)
        if (isBottomSide) roiRect.bottom = Math.max(newY, roiRect.top + 100)
    }

    private fun moveROI(dx: Float, dy: Float) {
        // Apply movement but ensure ROI stays within view bounds
        if (roiRect.left + dx >= 0 && roiRect.right + dx <= width) {
            roiRect.left += dx
            roiRect.right += dx
        }

        if (roiRect.top + dy >= 0 && roiRect.bottom + dy <= height) {
            roiRect.top += dy
            roiRect.bottom += dy
        }
    }
}

================
File: com/parakurom/lingoflow/CameraFragment.kt
================
package com.parakurom.lingoflow

import android.annotation.SuppressLint
import android.content.res.Configuration
import android.os.Bundle
import android.util.Log
import android.view.LayoutInflater
import android.view.View
import android.view.ViewGroup
import android.widget.Toast
import androidx.camera.core.AspectRatio
import androidx.camera.core.Camera
import androidx.camera.core.CameraSelector
import androidx.camera.core.ImageAnalysis
import androidx.camera.core.ImageProxy
import androidx.camera.core.Preview
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.camera.view.PreviewView
import androidx.core.content.ContextCompat
import androidx.fragment.app.Fragment
import androidx.navigation.Navigation
import androidx.recyclerview.widget.LinearLayoutManager
import androidx.recyclerview.widget.RecyclerView
import java.util.concurrent.ExecutorService
import java.util.concurrent.Executors
import java.util.concurrent.TimeUnit

class CameraFragment : Fragment(), GestureRecognizerHelper.GestureRecognizerListener {

    companion object {
        private const val TAG = "Hand gesture recognizer"
    }

    private lateinit var gestureRecognizerHelper: GestureRecognizerHelper
    private var defaultNumResults = 1
    private val gestureRecognizerResultAdapter: GestureRecognizerResultsAdapter by lazy {
        GestureRecognizerResultsAdapter().apply { updateAdapterSize(defaultNumResults) }
    }
    private var preview: Preview? = null
    private var imageAnalyzer: ImageAnalysis? = null
    private var camera: Camera? = null
    private var cameraProvider: ProcessCameraProvider? = null
    private var cameraFacing = CameraSelector.LENS_FACING_BACK

    /** Blocking ML operations are performed using this executor */
    private lateinit var backgroundExecutor: ExecutorService
    private lateinit var recyclerView: RecyclerView
    private lateinit var viewFinder: PreviewView
    private lateinit var overlay: OverlayView

    override fun onResume() {
        super.onResume()
        // Make sure that all permissions are still present, since the
        // user could have removed them while the app was in paused state.
        if (!PermissionsFragment.hasPermissions(requireContext())) {
            Navigation.findNavController(requireActivity(), R.id.fragment_container)
                    .navigate(R.id.action_camera_to_permissions)
        }

        // Start the GestureRecognizerHelper again when users come back
        // to the foreground.
        backgroundExecutor.execute {
            if (gestureRecognizerHelper.isClosed()) {
                gestureRecognizerHelper.setupGestureRecognizer()
            }
        }
    }

    override fun onPause() {
        super.onPause()
        if (this::gestureRecognizerHelper.isInitialized) {
            // Close the Gesture Recognizer helper and release resources
            backgroundExecutor.execute { gestureRecognizerHelper.clearGestureRecognizer() }
        }
    }

    override fun onDestroyView() {
        super.onDestroyView()

        // Shut down our background executor
        backgroundExecutor.shutdown()
        backgroundExecutor.awaitTermination(Long.MAX_VALUE, TimeUnit.NANOSECONDS)
    }

    override fun onCreateView(
        inflater: LayoutInflater,
        container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View {
        val view = inflater.inflate(R.layout.fragment_point_to_read, container, false)
        recyclerView = view.findViewById(R.id.recyclerview_results)
        viewFinder = view.findViewById(R.id.view_finder)
        overlay = view.findViewById(R.id.overlay)
        return view
    }

    @SuppressLint("MissingPermission")
    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        super.onViewCreated(view, savedInstanceState)
        recyclerView.layoutManager = LinearLayoutManager(requireContext())
        recyclerView.adapter = gestureRecognizerResultAdapter

        // Initialize our background executor
        backgroundExecutor = Executors.newSingleThreadExecutor()

        // Wait for the views to be properly laid out
        viewFinder.post {
            // Set up the camera and its use cases
            setUpCamera()
        }

        // Create the Hand Gesture Recognition Helper that will handle the
        // inference
        backgroundExecutor.execute {
            gestureRecognizerHelper =
                GestureRecognizerHelper(
                    context = requireContext(),
                    gestureRecognizerListener = this
                )
        }

        // Attach listeners to UI control widgets
    }

    // Initialize CameraX, and prepare to bind the camera use cases
    private fun setUpCamera() {
        val cameraProviderFuture = ProcessCameraProvider.getInstance(requireContext())
        cameraProviderFuture.addListener(
                {
                    // CameraProvider
                    cameraProvider = cameraProviderFuture.get()

                    // Build and bind the camera use cases
                    bindCameraUseCases()
                },
            ContextCompat.getMainExecutor(requireContext())
        )
    }

    // Declare and bind preview, capture and analysis use cases
    @SuppressLint("UnsafeOptInUsageError")
    private fun bindCameraUseCases() {

        // CameraProvider
        val cameraProvider =
                cameraProvider ?: throw IllegalStateException("Camera initialization failed.")

        val cameraSelector = CameraSelector.Builder().requireLensFacing(cameraFacing).build()

        // Preview. Only using the 4:3 ratio because this is the closest to our models
        preview =
                Preview.Builder()
                        .setTargetAspectRatio(AspectRatio.RATIO_4_3)
                        .setTargetRotation(viewFinder.display.rotation)
                        .build()

        // ImageAnalysis. Using RGBA 8888 to match how our models work
        imageAnalyzer =
                ImageAnalysis.Builder()
                        .setTargetAspectRatio(AspectRatio.RATIO_4_3)
                        .setTargetRotation(viewFinder.display.rotation)
                        .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                        .setOutputImageFormat(ImageAnalysis.OUTPUT_IMAGE_FORMAT_RGBA_8888)
                        .build()
                        // The analyzer can then be assigned to the instance
                        .also {
                            it.setAnalyzer(backgroundExecutor) { image -> recognizeHand(image) }
                        }

        // Must unbind the use-cases before rebinding them
        cameraProvider.unbindAll()

        try {
            // A variable number of use-cases can be passed here -
            // camera provides access to CameraControl & CameraInfo
            camera = cameraProvider.bindToLifecycle(this, cameraSelector, preview, imageAnalyzer)

            // Attach the viewfinder's surface provider to preview use case
            preview?.setSurfaceProvider(viewFinder.surfaceProvider)
        } catch (exc: Exception) {
            Log.e(TAG, "Use case binding failed", exc)
        }
    }

    private fun recognizeHand(imageProxy: ImageProxy) {
        gestureRecognizerHelper.recognizeLiveStream(
                imageProxy = imageProxy,
        )
    }

    override fun onConfigurationChanged(newConfig: Configuration) {
        super.onConfigurationChanged(newConfig)
        imageAnalyzer?.targetRotation = viewFinder.display.rotation
    }

    // Update UI after a hand gesture has been recognized. Extracts original
    // image height/width to scale and place the landmarks properly through
    // OverlayView. Only one result is expected at a time. If two or more
    // hands are seen in the camera frame, only one will be processed.
    override fun onResults(resultBundle: GestureRecognizerHelper.ResultBundle) {
        activity?.runOnUiThread {
            if (::overlay.isInitialized) {
                // Show result of recognized gesture
                val gestureCategories = resultBundle.results.first().gestures()
                gestureRecognizerResultAdapter.updateResults(
                        if (gestureCategories.isNotEmpty()) gestureCategories.first()
                        else emptyList()
                )

                // Pass necessary information to OverlayView for drawing on the canvas
                overlay.setResults(
                        resultBundle.results.first(),
                        resultBundle.inputImageHeight,
                        resultBundle.inputImageWidth,
                )

                // Force a redraw
                overlay.invalidate()
            }
        }
    }

    override fun onError(error: String) {
        activity?.runOnUiThread {
            Toast.makeText(requireContext(), error, Toast.LENGTH_SHORT).show()
            gestureRecognizerResultAdapter.updateResults(emptyList())
        }
    }
}

================
File: com/parakurom/lingoflow/GestureRecognizerHelper.kt
================
package com.parakurom.lingoflow

import android.content.Context
import android.graphics.Bitmap
import android.graphics.Matrix
import android.os.SystemClock
import android.util.Log
import androidx.annotation.VisibleForTesting
import androidx.camera.core.ImageProxy
import com.google.mediapipe.framework.image.BitmapImageBuilder
import com.google.mediapipe.framework.image.MPImage
import com.google.mediapipe.tasks.core.BaseOptions
import com.google.mediapipe.tasks.core.Delegate
import com.google.mediapipe.tasks.vision.core.RunningMode
import com.google.mediapipe.tasks.vision.gesturerecognizer.GestureRecognizer
import com.google.mediapipe.tasks.vision.gesturerecognizer.GestureRecognizerResult

class GestureRecognizerHelper(
    val context: Context,
    val gestureRecognizerListener: GestureRecognizerListener? = null
) {

    // For this example this needs to be a var so it can be reset on changes. If the
    // GestureRecognizer will not change, a lazy val would be preferable.
    private var gestureRecognizer: GestureRecognizer? = null

    init {
        setupGestureRecognizer()
    }

    fun clearGestureRecognizer() {
        gestureRecognizer?.close()
        gestureRecognizer = null
    }

    // Initialize the gesture recognizer using current settings on the thread that is using it. CPU
    // can be used with recognizers that are created on the main thread and used on a background
    // thread, but the GPU delegate needs to be used on the thread that initialized the recognizer
    fun setupGestureRecognizer() {
        // Set general recognition options, including number of used threads
        val baseOptionBuilder = BaseOptions.builder()

        // Use the specified hardware for running the model. Default to CPU
        baseOptionBuilder.setDelegate(Delegate.CPU)

        baseOptionBuilder.setModelAssetPath("gesture_recognizer_custom.task")

        try {
            val baseOptions = baseOptionBuilder.build()
            val optionsBuilder =
                    GestureRecognizer.GestureRecognizerOptions.builder()
                            .setBaseOptions(baseOptions)
                            .setRunningMode(RunningMode.LIVE_STREAM)

            optionsBuilder
                    .setResultListener(this::returnLivestreamResult)
                    .setErrorListener(this::returnLivestreamError)

            val options = optionsBuilder.build()
            gestureRecognizer = GestureRecognizer.createFromOptions(context, options)
        } catch (e: IllegalStateException) {
            gestureRecognizerListener?.onError(
                    "Gesture recognizer failed to initialize. See error logs for details"
            )
            Log.e(TAG, "MP Task Vision failed to load the task with error: " + e.message)
        } catch (e: RuntimeException) {
            gestureRecognizerListener?.onError(
                    "Gesture recognizer failed to initialize. See error logs for details"
            )
            Log.e(TAG, "MP Task Vision failed to load the task with error: " + e.message)
        }
    }

    // Convert the ImageProxy to MP Image and feed it to GestureRecognizer.
    fun recognizeLiveStream(
        imageProxy: ImageProxy,
    ) {
        val frameTime = SystemClock.uptimeMillis()

        // Copy out RGB bits from the frame to a bitmap buffer
        val bitmapBuffer =
            Bitmap.createBitmap(imageProxy.width, imageProxy.height, Bitmap.Config.ARGB_8888)
        imageProxy.use { bitmapBuffer.copyPixelsFromBuffer(imageProxy.planes[0].buffer) }
        imageProxy.close()

        val matrix =
                Matrix().apply {
                    // Rotate the frame received from the camera to be in the same direction as
                    // it'll be shown
                    postRotate(imageProxy.imageInfo.rotationDegrees.toFloat())

                    // flip image since we only support front camera
//                    postScale(-1f, 1f, imageProxy.width.toFloat(), imageProxy.height.toFloat())
                }

        // Rotate bitmap to match what our model expects
        val rotatedBitmap =
            Bitmap.createBitmap(
                bitmapBuffer,
                0,
                0,
                bitmapBuffer.width,
                bitmapBuffer.height,
                matrix,
                true
            )

        // Convert the input Bitmap object to an MPImage object to run inference
        val mpImage = BitmapImageBuilder(rotatedBitmap).build()

        recognizeAsync(mpImage, frameTime)
    }

    // Run hand gesture recognition using MediaPipe Gesture Recognition API
    @VisibleForTesting
    fun recognizeAsync(mpImage: MPImage, frameTime: Long) {
        // As we're using running mode LIVE_STREAM, the recognition result will be returned in
        // returnLivestreamResult function
        gestureRecognizer?.recognizeAsync(mpImage, frameTime)
    }

    // Return running status of the recognizer helper
    fun isClosed(): Boolean {
        return gestureRecognizer == null
    }

    // Return the recognition result to the GestureRecognizerHelper's caller
    private fun returnLivestreamResult(result: GestureRecognizerResult, input: MPImage) {
        gestureRecognizerListener?.onResults(
            ResultBundle(listOf(result), input.height, input.width)
        )
    }

    // Return errors thrown during recognition to this GestureRecognizerHelper's caller
    private fun returnLivestreamError(error: RuntimeException) {
        gestureRecognizerListener?.onError(error.message ?: "An unknown error has occurred")
    }

    companion object {
        val TAG = "GestureRecognizerHelper ${this.hashCode()}"
    }

    data class ResultBundle(
        val results: List<GestureRecognizerResult>,
        val inputImageHeight: Int,
        val inputImageWidth: Int,
    )

    interface GestureRecognizerListener {
        fun onError(error: String)
        fun onResults(resultBundle: ResultBundle)
    }
}

================
File: com/parakurom/lingoflow/GestureRecognizerResultsAdapter.kt
================
package com.parakurom.lingoflow

import android.annotation.SuppressLint
import android.view.LayoutInflater
import android.view.View
import android.view.ViewGroup
import android.widget.TextView
import androidx.recyclerview.widget.RecyclerView
import com.google.mediapipe.tasks.components.containers.Category
import java.util.Locale
import kotlin.math.min

class GestureRecognizerResultsAdapter :
        RecyclerView.Adapter<GestureRecognizerResultsAdapter.ViewHolder>() {

    private var adapterCategories: MutableList<Category?> = mutableListOf()
    private var adapterSize: Int = 0

    @SuppressLint("NotifyDataSetChanged")
    fun updateResults(categories: List<Category>?) {
        adapterCategories = MutableList(adapterSize) { null }
        if (categories != null) {
            val sortedCategories = categories.sortedByDescending { it.score() }
            val min = min(sortedCategories.size, adapterCategories.size)
            for (i in 0 until min) {
                adapterCategories[i] = sortedCategories[i]
            }
            adapterCategories.sortedBy { it?.index() }
            notifyDataSetChanged()
        }
    }

    fun updateAdapterSize(size: Int) {
        adapterSize = size
    }

    override fun onCreateViewHolder(parent: ViewGroup, viewType: Int): ViewHolder {
        val view =
                LayoutInflater.from(parent.context)
                        .inflate(R.layout.item_gesture_recognizer_result, parent, false)
        return ViewHolder(view)
    }

    override fun onBindViewHolder(holder: ViewHolder, position: Int) {
        adapterCategories[position].let { category ->
            holder.bind(category?.categoryName(), category?.score())
        }
    }

    override fun getItemCount(): Int = adapterCategories.size

    inner class ViewHolder(view: View) : RecyclerView.ViewHolder(view) {

        private val tvLabel: TextView = view.findViewById(R.id.tvLabel)
        private val tvScore: TextView = view.findViewById(R.id.tvScore)

        fun bind(label: String?, score: Float?) {
            tvLabel.text = label ?: "--"
            tvScore.text = if (score != null) String.format(Locale.US, "%.2f", score) else "--"
        }
    }
}

================
File: com/parakurom/lingoflow/MainActivity.kt
================
package com.parakurom.lingoflow

import android.os.Bundle
import androidx.appcompat.app.AppCompatActivity

class MainActivity : AppCompatActivity() {

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)
    }
}

================
File: com/parakurom/lingoflow/OverlayView.kt
================
package com.parakurom.lingoflow

import android.content.Context
import android.graphics.Canvas
import android.graphics.Color
import android.graphics.Paint
import android.util.AttributeSet
import android.view.View
import com.google.mediapipe.tasks.vision.gesturerecognizer.GestureRecognizerResult
import com.google.mediapipe.tasks.vision.handlandmarker.HandLandmarker
import java.util.LinkedList
import kotlin.math.max

class OverlayView(context: Context?, attrs: AttributeSet?) : View(context, attrs) {

    private var results: GestureRecognizerResult? = null

    private val linePaint = Paint().apply {
        color = Color.BLUE
        strokeWidth = 8f
        style = Paint.Style.STROKE
    }

    private val pointPaint = Paint().apply {
        color = Color.YELLOW
        strokeWidth = 8f
        style = Paint.Style.FILL
    }

    // Trail properties
    private val trailPaint = Paint().apply {
        color = Color.RED
        strokeWidth = 6f
        style = Paint.Style.STROKE
    }

    private var scaleFactor = 1f
    private var imageWidth = 1
    private var imageHeight = 1

    // Store the last few middle fingertip positions for the trail effect
    private val middleFingerTrail = LinkedList<Pair<Float, Float>>()
    private val trailSize = 10  // Number of points to keep for the vanishing effect

    override fun draw(canvas: Canvas) {
        super.draw(canvas)
        results?.let { gestureRecognizerResult ->
            gestureRecognizerResult.landmarks().forEach { landmark ->
                landmark.forEach { normalizedLandmark ->
//                    canvas.drawPoint(
//                        normalizedLandmark.x() * imageWidth * scaleFactor,
//                        normalizedLandmark.y() * imageHeight * scaleFactor,
//                        pointPaint
//                    )
                }

                HandLandmarker.HAND_CONNECTIONS.forEach { connection ->
                    val start = landmark[connection!!.start()]
                    val end = landmark[connection.end()]
//                    canvas.drawLine(
//                        start.x() * imageWidth * scaleFactor,
//                        start.y() * imageHeight * scaleFactor,
//                        end.x() * imageWidth * scaleFactor,
//                        end.y() * imageHeight * scaleFactor,
//                        linePaint
//                    )
                }

                // Get middle fingertip position (Landmark Index 12)
                val middleFingertip = landmark[12]
                val x = middleFingertip.x() * imageWidth * scaleFactor
                val y = middleFingertip.y() * imageHeight * scaleFactor

                // Add new position to trail list
                middleFingerTrail.addFirst(x to y)

                // Keep only the latest `trailSize` points
                if (middleFingerTrail.size > trailSize) {
                    middleFingerTrail.removeLast()
                }

                // Draw vanishing trail
                for (i in 1 until middleFingerTrail.size) {
                    val (x1, y1) = middleFingerTrail[i - 1]
                    val (x2, y2) = middleFingerTrail[i]

                    // Adjust alpha for fading effect
                    trailPaint.alpha = (255 * (1 - (i.toFloat() / trailSize))).toInt()

                    canvas.drawLine(x1, y1, x2, y2, trailPaint)
                }
            }
        }
    }

    fun setResults(
        gestureRecognizerResult: GestureRecognizerResult,
        imageHeight: Int,
        imageWidth: Int,
    ) {
        results = gestureRecognizerResult

        this.imageHeight = imageHeight
        this.imageWidth = imageWidth

        // Scale landmarks to match displayed size
        scaleFactor = max(width * 1f / imageWidth, height * 1f / imageHeight)

        invalidate()
    }
}

================
File: com/parakurom/lingoflow/PermissionsFragment.kt
================
package com.parakurom.lingoflow

import android.Manifest
import android.content.Context
import android.content.pm.PackageManager
import android.os.Bundle
import android.widget.Toast
import androidx.activity.result.contract.ActivityResultContracts
import androidx.core.content.ContextCompat
import androidx.fragment.app.Fragment
import androidx.lifecycle.lifecycleScope
import androidx.navigation.Navigation

private val PERMISSIONS_REQUIRED = arrayOf(Manifest.permission.CAMERA)


class PermissionsFragment : Fragment() {

    private val requestPermissionLauncher =
        registerForActivityResult(
            ActivityResultContracts.RequestPermission()
        ) { isGranted: Boolean ->
            if (isGranted) {
                Toast.makeText(
                    context,
                    "Permission request granted",
                    Toast.LENGTH_LONG
                ).show()
                navigateToCamera()
            } else {
                Toast.makeText(
                    context,
                    "Permission request denied",
                    Toast.LENGTH_LONG
                ).show()
            }
        }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        when (PackageManager.PERMISSION_GRANTED) {
            ContextCompat.checkSelfPermission(
                requireContext(),
                Manifest.permission.CAMERA
            ) -> {
                navigateToCamera()
            }
            else -> {
                requestPermissionLauncher.launch(
                    Manifest.permission.CAMERA
                )
            }
        }
    }

    private fun navigateToCamera() {
        lifecycleScope.launchWhenStarted {
            Navigation.findNavController(
                requireActivity(),
                R.id.fragment_container
            ).navigate(
                R.id.action_permissions_to_camera
            )
        }
    }

    companion object {

        /** Convenience method used to check if all permissions required by this app are granted */
        fun hasPermissions(context: Context) = PERMISSIONS_REQUIRED.all {
            ContextCompat.checkSelfPermission(
                context,
                it
            ) == PackageManager.PERMISSION_GRANTED
        }
    }
}

================
File: com/parakurom/lingoflow/WelcomeFragment.kt
================
package com.parakurom.lingoflow

import android.os.Bundle
import android.view.LayoutInflater
import android.view.View
import android.view.ViewGroup
import androidx.fragment.app.Fragment
import androidx.navigation.Navigation

class WelcomeFragment : Fragment() {

    override fun onCreateView(
        inflater: LayoutInflater,
        container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View {
        val view = inflater.inflate(R.layout.fragment_welcome, container, false)

        view.findViewById<View>(R.id.button_auto_read).setOnClickListener {
            Navigation.findNavController(view)
                .navigate(R.id.action_welcome_to_auto_read)
        }

        // Point to Read Mode (Navigates to Camera)
        view.findViewById<View>(R.id.button_point_to_read).setOnClickListener {
            Navigation.findNavController(view)
                .navigate(R.id.action_welcome_to_permission)
        }

        return view
    }
}
